{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we tell real sequences from fake, random sequences? Find out in this next episode!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D,Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding Scheme\n",
    "# A: 1\n",
    "# C: 2\n",
    "# G: 3\n",
    "# T: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Fake Sequences\n",
    "seq_length = 10000\n",
    "num_seqs = 3500\n",
    "fake_seqs = np.random.randint(4,size=(num_seqs,seq_length))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5260487"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(big_seq)-(10000*3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get real sequences\n",
    "big_seq = big_seq.replace(\" \",\"\")\n",
    "big_seq = big_seq.replace(\"\\n\",\"\")\n",
    "real_seqs = np.zeros((num_seqs, seq_length))\n",
    "for i in range(num_seqs):\n",
    "    seq = big_seq[i*seq_length: (i+1)*seq_length]\n",
    "    vec = seq_to_vec(seq)\n",
    "    real_seqs[i] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((2*num_seqs, seq_length))\n",
    "y = np.zeros(2*num_seqs)\n",
    "\n",
    "X[:num_seqs] = fake_seqs\n",
    "y[:num_seqs] = 0\n",
    "\n",
    "X[num_seqs:] = real_seqs\n",
    "y[num_seqs:] = 1\n",
    "\n",
    "max_length = seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39600480"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(big_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_110 (Dense)            (None, 1000)              10001000  \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 10,131,501\n",
      "Trainable params: 10,131,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 4200 samples, validate on 1050 samples\n",
      "Epoch 1/100\n",
      "4200/4200 [==============================] - 23s - loss: 1.8281 - acc: 0.4967 - val_loss: 0.9329 - val_acc: 0.5086\n",
      "Epoch 2/100\n",
      "4200/4200 [==============================] - 18s - loss: 0.8023 - acc: 0.5060 - val_loss: 0.9145 - val_acc: 0.4914\n",
      "Epoch 3/100\n",
      "1184/4200 [=======>......................] - ETA: 13s - loss: 0.9341 - acc: 0.5025"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-383-6d31ba4da67b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mvmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mvmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vmodel = Sequential()\n",
    "vmodel.add(Dense(1000, activation='relu',input_dim=max_length))\n",
    "#model.add(Dropout(0.5))\n",
    "vmodel.add(Dense(100, activation='relu'))\n",
    "vmodel.add(Dense(100, activation='relu'))\n",
    "\n",
    "vmodel.add(Dense(100, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "vmodel.add(Dense(100, activation='relu',input_dim=max_length))\n",
    "vmodel.add(Dense(1, activation='sigmoid'))\n",
    "vmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(vmodel.summary())\n",
    "vmodel.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_exp = np.expand_dims(X_train, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4200 samples, validate on 1050 samples\n",
      "Epoch 1/10\n",
      "4200/4200 [==============================] - 34s - loss: 0.6929 - acc: 0.5171 - val_loss: 0.6924 - val_acc: 0.4886\n",
      "Epoch 2/10\n",
      "4200/4200 [==============================] - 28s - loss: 0.6830 - acc: 0.5805 - val_loss: 0.6629 - val_acc: 0.5114\n",
      "Epoch 3/10\n",
      "4200/4200 [==============================] - 24s - loss: 0.6075 - acc: 0.7100 - val_loss: 0.4936 - val_acc: 0.8362\n",
      "Epoch 4/10\n",
      "4200/4200 [==============================] - 25s - loss: 0.3896 - acc: 0.8679 - val_loss: 0.2885 - val_acc: 0.9010\n",
      "Epoch 5/10\n",
      "4200/4200 [==============================] - 26s - loss: 0.2283 - acc: 0.9379 - val_loss: 0.1343 - val_acc: 0.9971\n",
      "Epoch 6/10\n",
      "4200/4200 [==============================] - 26s - loss: 0.1387 - acc: 0.9648 - val_loss: 0.0699 - val_acc: 0.9886\n",
      "Epoch 7/10\n",
      "4200/4200 [==============================] - 26s - loss: 0.0757 - acc: 0.9883 - val_loss: 0.0350 - val_acc: 0.9990\n",
      "Epoch 8/10\n",
      "4200/4200 [==============================] - 25s - loss: 0.0487 - acc: 0.9933 - val_loss: 0.0206 - val_acc: 0.9990\n",
      "Epoch 9/10\n",
      "4200/4200 [==============================] - 25s - loss: 0.0312 - acc: 0.9964 - val_loss: 0.0117 - val_acc: 0.9990\n",
      "Epoch 10/10\n",
      "4200/4200 [==============================] - 27s - loss: 0.0253 - acc: 0.9971 - val_loss: 0.0131 - val_acc: 0.9990\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(16, 2, activation='relu', input_shape=(seq_length,1)))\n",
    "model.add(Conv1D(16, 2, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Conv1D(16, 3, activation='relu'))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_exp, y_train, batch_size=16, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VNXZwPHfkwUSSFgDYQmQsK8CGgEFFcUFUat1Q9xa\ntUVbFbVu2LfrW+v+ttW6FSu17lXEuqG4BUQFBWTfSQgkYUsCCUlIQpJ53j/uJAwhgUkyN5Nknu/n\nM5+Zucu5zwzkPnPPueccUVWMMcYYgLBgB2CMMabpsKRgjDGmiiUFY4wxVSwpGGOMqWJJwRhjTBVL\nCsYYY6pYUjDNlogkioiKSIQf2/5URL5upLiiReQDEckXkbcb45jGBIolBdMoRCRdRA6JSFy15Su8\nJ/bE4ER2RHIp9D7SRWRmA4q8HIgHOqvqFQEK05hGYUnBNKZtwLTKNyIyAmgTvHCO0kFVY3Bi/J2I\nTK5rASISDvQBNqtqeT32P+5VjzFusqRgGtMrwPU+738CvOy7gYi0F5GXRSRbRLaLyG9EJMy7LlxE\nnhCRHBFJAy6oYd8XRWSXiGSJyIPek3SdqOpiYB0w3FvuYBH5TET2icgmEbnS55gvichzIjJPRIqA\nr4DfAVO9Vx03iUiY93NsF5G93s/X3rt/5VXKTSKyA/jSZ9kNIpIhIvtF5BYROVlEVotInog87RND\nPxH5UkRyvd/NayLSwWd9uojc4903X0T+IyJRPusvFpGVInJARFIrk2Ggvk/TzKiqPezh+gNIB84G\nNgFDgHAgE+dXtQKJ3u1eBt4DYoFEYDNwk3fdLcBGoBfQCUjx7hvhXf8u8A+gLdAV+B642bvup8DX\ntcSWWFkOIMB44CAwyVtWBnCDd/1oIAcY6t33JSDfu08YEAX8AXjVp/wbga1AXyAGmAu8Uu3YL3uP\nFe2z7HlveecCJcB/vZ+rJ7AXOMNbRn/gHKA10AUnMf2t2nf/PdDD+71tAG7xrhvjjf8cb/w9gcHH\n+z7t0XIfQQ/AHqHx8EkKvwEeBiYDn3lPtOo9EYYDhypPuN79bgYWeF9/WXky874/1+dkHg+UAtE+\n66cBKd7X/iSFPGC/96Q5w7tuKrCo2vb/AH7vff0S8HK19dWTwhfAL33eDwLKvHFXHrtvDfH09FmW\nC0z1ef8OcGctn+cSYEW17/5an/ePAc/7fJa/1lDGMb9Pe7Tch9Vfmsb2Cs4v2SSqVR0BcUAksN1n\n2XacX6/g/NLNqLauUh/vvrtEpHJZWLXtjydOj24H6AOMFZE8n2UR3s9R6XjH6MHRn6kykR2rjD0+\nr4treB8DICLxwJPAaThXWGE4yc3Xbp/XB70xgXPVNa+GYwfi+zTNkCUF06hUdbuIbAOmADdVW52D\n8wu6D7Deu6w3kOV9vQvnJIbPukoZOL9sazqxN0QGsFBVzznGNscbangnzmeq1BsoxznJJ/hZxrE8\n5N1/hKruE5FLgKePs0+lDKBfLcvd+D5NE2cNzSYYbgLOUtUi34WqWgG8BfxZRGJFpA/wK+BV7yZv\nATNEJEFEOgIzffbdBXwK/J+ItPM27vYTkTMaGOuHwEARuU5EIr2Pk0VkSB3KeAO4S0SSRCQG5yT+\nnwCebGOBQiBfRHoC99Zh3xeBG0Rkkvc76ykig138Pk0TZ0nBNDpVTVXVZbWsvh0oAtKAr4HXgdne\ndS8A84FVwA84Dba+rgda4Vxl7AfmAN0bGGsBTtvFVTi/+HcDj+I06vprNoerzbbhNBrf3pC4qvkj\ncCJOg/FHHP291EpVv8dpRP+rd/+FHL6qCfj3aZo+UbVJdowxxjjsSsEYY0wVSwrGGGOqWFIwxhhT\nxZKCMcaYKs2un0JcXJwmJiYGOwxjjGlWli9fnqOqXY63XbNLComJiSxbVtvdjMYYY2oiItuPv5VV\nHxljjPFhScEYY0wVSwrGGGOqNLs2hZqUlZWRmZlJSUlJsENxXVRUFAkJCURGRgY7FGNMC9QikkJm\nZiaxsbEkJibiM8xvi6Oq5ObmkpmZSVJSUrDDMca0QK5VH4nIbO/Ug2trWS8i8pSIbPVOE3hifY9V\nUlJC586dW3RCABAROnfuHBJXRMaY4HCzTeElnNm1anM+MMD7mA4815CDtfSEUClUPqcxJjhcqz5S\n1a9EJPEYm1yMM42hAktEpIOIdPeO426MaUwlByA/A/IynOeibLARlJue3uOg/yRXDxHMNoWeHDm1\nX6Z32VFJQUSm41xN0Lt37+qrgy4vL4/XX3+dX/7yl3Xab8qUKbz++ut06NDBpciMX4r3w7x7obQQ\nYuMhptvRzzFdIbyZNu57PM5JPj8D8nY4z/mZhxNAfgaU5NewY8u7KnU7zbld/vqkGxnegpOC31R1\nFjALIDk5ucn9fMnLy+PZZ589KimUl5cTEVH7VzxvXk1T45pGVVYMb0yDzGXQZRBkLoWDOTVsKNA2\nruaEERsPsd0hJt55REY17mcoPwQHKk/ymUf+4s/PgPwsqCg9cp/W7aFDL2jfC/qcCu0TnNcdejuv\n23aFsMa7Y11VKS33UFBSTkFJGYWl5RSUlFNUWk5xWQWlZR5KyisoKaugpMxz+Nm7rLRyWbmzvPiQ\n87pqeVkFJeUeKjz1P32IQJgIYeJU44ZVvZcj1oWJEBZ27PVSbV14mBy/7DC4aEgPhgfwe69JMJNC\nFkfOt5vA4bl4m5WZM2eSmprKqFGjiIyMJCoqio4dO7Jx40Y2b97MJZdcQkZGBiUlJdxxxx1Mnz4d\nODxkR2FhIeeffz4TJkzg22+/pWfPnrz33ntER0cH+ZO1cBXlMOdG2LEELp8Nwy/1Li+Dwr1QuBsK\n9nifvY/CPc7znnXONlpxdLlRHSC2m5MgYrt5X/smEe+61jH+xVm9aueI15lOPNV/o8Z0c0763UfB\nkIucE377Xt5EkABR7Rv01fnyeJTCQ85JvNB7Ui8oKaeg9PDrWpd7T/4FJWWUVfh/wg4PE6Ijw4mK\nDKN1hPMcFRnufYTRITqSqMhwWlcujwgnulUYURGHt2lduX3EkftWbh/V6vDryHAJmfa8YCaF94Hb\nRORNYCyQH4j2hD9+sI71Ow80ODhfQ3u04/cXDat1/SOPPMLatWtZuXIlCxYs4IILLmDt2rVVt43O\nnj2bTp06UVxczMknn8xll11G586djyhjy5YtvPHGG7zwwgtceeWVvPPOO1x77bUB/RzGhyp8eCds\nmgdTnjicEMCpJmrf03kci6cCDub6JIxqSaRwD2xf7LyvOHT0/q1ijk4Y0R2d/Xx/8ZdWq9oJb+X9\nZZ8A/SYdPtFXnvTb9YSIuswW6vu1KFv3FrI6M58DJWXOydznJF79l3zlif14wgRioyKJaR1BbJTz\niG8XRf+oCO+yyKrlsVERxLaOJMa77vCJ//BJOzLc+t26xbWkICJvABOBOBHJBH4PRAKo6vPAPGAK\nsBU4iDNPbIswZsyYI/oRPPXUU7z77rsAZGRksGXLlqOSQlJSEqNGjQLgpJNOIj09vdHiDUlf/glW\nvAKn3wdjfl6/MsLCnbaGmK7Q/YTat1N12i2OShw+zztXOOvLDvpU7SRA71MOV/NUnvQDXLWTXVDK\nN1tzWLQlh6+3ZrPnwJFVTVGRYc5J23tCj4mKoGtsVNXr2KhI2lU7ucdERdDOuy6mdQRtWoWHzC/t\n5s7Nu4+mHWe9ArcG+rjH+kXfWNq2bVv1esGCBXz++ecsXryYNm3aMHHixBr7GbRuffiXXXh4OMXF\nxY0Sa0ha8jws+j846adw5q/dP54ItOnkPOKH1r6dKpSXut4mUXyogu/T9/H1lmwWbclh4+4CADq0\niWR8vzgmDIjj5MROdG7biratI2gVYb/KQ0mzaGhu6mJjYykoKKhxXX5+Ph07dqRNmzZs3LiRJUuW\nNHJ05ghr5sAnM2HwhXDBX5wTdlMh4kpC8HiU9bsOVF0JLE3fz6FyD63CwzipT0fuPW8Qpw2IY1iP\n9oSHNaHvwwSFJYUA6Ny5M+PHj2f48OFER0cTHx9ftW7y5Mk8//zzDBkyhEGDBjFu3LggRhriUr+E\nd29x7ra57EWn+qeFysorrroS+DY1l31FTpvG4G6xXD+uDxMGxDEmqRNtWtkpwBxJtJl1UElOTtbq\nk+xs2LCBIUOGBCmixhdqnzcgsn6Aly6ETknw048gumX1DSkoKWNJ2j4Wbcnm6y05pOUUAdAltjWn\n9XeqhCb0j6Nru0a+XdY0GSKyXFWTj7ed/UwwLV/OVnjtcmjbGa6Z0yISQnmFh1WZeU6V0JYcVmTk\nUeFRoiPDGdu3E1eP7c1pA7owMD7GGnhNnVhSMC1bwW549cfO62vfhXbdgxtPPakq23KK+Np7l9CS\n1FwKSssRgRN6tueWM/oyoX8XTuzTgdYRLbdazLjPkoJpuYrz4NXLoCgXfvohxPUPdkR1sr/oEN+k\nOlcCi7bkkJXn3JGW0DGaC0d2Z0L/LpzarzMd27YKcqSmJbGkYFqmshJ482rI3gTXvAU96z0ye6Mp\nq/CwNH1fVZXQ2p35qEJs6whO7d+ZWyb247T+cfTp3MaqhIxrLCmYlsdTAe/cBNu/ce4y6ndWsCOq\nVUFJGQs2ZfPZ+j2kbNpLQUk5EWHC6N4duHPSQCYMiGNkQnsirAevaSSWFEzLogof/Qo2fgiTH4UR\nlwc7oqPszCvm8w17+Gz9Hpak5VJWoXRq24rJw7px9tB4xvePI6a1/Wma4LD/eUEQExNDYWFhsMNo\nmRY8DMtfggm/gnG3BDsawGkk3rCrgM/W7+GzDbtZm+WMzdU3ri03jk/i7KHxnNi7o3UcM02CJQXT\ncnz/Aix8FEZfC5N+F9RQyio8fL9tn5MI1u8hK68YERjdqwP3Tx7MOUPj6d/Vz1FSjWlElhQCYObM\nmfTq1Ytbb3WGcvrDH/5AREQEKSkp7N+/n7KyMh588EEuvvjiIEfagq1715koZ9AUuPDJoAxfUVBS\nxsLN3vaBjXs5UFJO64gwThsQx4xJ/TlrcDxdYus3eqkxjaXlJYWPZ8LuNYEts9sIOP+RWldPnTqV\nO++8syopvPXWW8yfP58ZM2bQrl07cnJyGDduHD/60Y/srhE3pC2EudOdqQovnw3hjfffeld+MZ9v\n2Mtn6/ewODWnqn3g3GHdOGdoPKcNiLOhJEyzYv9bA2D06NHs3buXnTt3kp2dTceOHenWrRt33XUX\nX331FWFhYWRlZbFnzx66desW7HBblp0r4c1roFM/mPYGRLo7MZGqsnF3QVW10JosZ66DpLi23DA+\nibOHxHNSH2sfMM1Xy0sKx/hF76YrrriCOXPmsHv3bqZOncprr71GdnY2y5cvJzIyksTExBqHzDYN\nkJvqDF8R3QGum+tMUOOC8goP36cfbh/I3O+0D4zq1YH7Jg/i3KHx9Otiw0mYlqHlJYUgmTp1Kj//\n+c/Jyclh4cKFvPXWW3Tt2pXIyEhSUlLYvn17sENsWQr2wKuXOn0Srp0L7XoEtPjC0nIWbsrms/W7\nSdmUTX5xGa0iwpjQP45bz+zPpCFd6Rprg8uZlseSQoAMGzaMgoICevbsSffu3bnmmmu46KKLGDFi\nBMnJyQwePDjYIbYcJQfgtcucOZJ/8gF0GRiQYvccKKm6GlicmsuhCg8d20Ry9pB4zhkaz+kDrX3A\ntHz2PzyA1qw53MAdFxfH4sWLa9zO+ig0QOXwFXs3wLT/QMJxRwI+rvScIu6bs5rv0/cBkNi5DT85\ntU9V+4D1JjahxJKCaT48FfDudEhfBD+eBQPObnCRCzbtZcYbKwgLE+49z2kf6N/V2gdM6LKkYJoH\nVacfwvr34Nw/w8ipDSxOeW5hKo/P38Tgbu2Ydd1J9OrUJkDBGtN8tZikoKoh8euuuc2UFzALH4Nl\nL8L4O+DU2xpUVFFpOffNWc1Ha3Zx0cgePHrZCGsrMMarRfwlREVFkZubS+fOnVt0YlBVcnNziYoK\nsbtelr4ICx6CkVfD2X9sUFHbc4uY/vJytuwt4NdTBvPz0/q26P8zxtRVi0gKCQkJZGZmkp2dHexQ\nXBcVFUVCQkKww2g869+Dj+6GAefBj55q0PAVCzdnM+ONFQD8+8YxnDagS6CiNKbFaBFJITIykqSk\npGCHYQJt2yJ452eQcDJc8RKER9arGFXlH1+l8dgnGxkYH8us65Lp3dnaD4ypSYtICqYF2rXaufW0\nYxJc/R9oVb+T+MFD5dw7ZzUfrd7FBSd05/HLT7D2A2OOwf46TNOzb5szfEXrWGf4ijad6lXMjtyD\nTH9lGZv3FDDz/MHcfLq1HxhzPJYUTNNSmO0MX1FxCK5/H9rXr/1k0ZZsbnt9BarKv24YwxkDrf3A\nGH9YUjBNR2mBM3zFgV3wk/eha92HBlFVXliUxiMfb2RA11hmXX8SfTq3dSFYY1omSwqmaSgvdYbA\n3r3WGQK715g6F1F8qIL731nN+6t2MmVENx6/fCRtba5jY+rE1UFdRGSyiGwSka0iMrOG9R1F5F0R\nWS0i34vIcDfjMU2UxwPv3gLbFsLFz8DA8+pcRMa+g1z63Ld8sHon900exDNXn2gJwZh6cO2vRkTC\ngWeAc4BMYKmIvK+q6302+zWwUlV/LCKDvdtPcism0wSpwif3w7q5cM7/wqhpdS7im6053Pr6D3g8\nyuyfnsyZg7q6EKgxocHNK4UxwFZVTVPVQ8CbQPVJiocCXwKo6kYgUUTiXYzJNCWqsOAR+H4WnHIb\nnDqjjrsr/1yUxnUvfkfX2Na8f9sESwjGNJCb19c9gQyf95nA2GrbrAIuBRaJyBigD5AA7HExLtMU\nHNwH790Gmz6CkdPgnD/Vqbdy8aEKZs5dzXsrdzJ5WDeeuHIkMVZdZEyDBfuv6BHgSRFZCawBVgAV\n1TcSkenAdIDevXs3aoDGBRnfw5wboWA3nPcwjPtFnRJCxr6D3PzKcjbsPsA95w7k1jP7W/8DYwLE\nzaSQBfTyeZ/gXVZFVQ8ANwCI81e9DUirXpCqzgJmASQnJ4foMKEtgMcD3z4JX/wJOvSCmz6FnifW\nqYhvve0H5R7lxZ8kc9Zgq200JpDcTApLgQEikoSTDK4CrvbdQEQ6AAe9bQ4/A77yJgrT0hRmw7s3\nQ+oXMPQSZ3C7qPZ+766qzP4mnYfmbSApri0vXJ9MUpz1PzAm0FxLCqpaLiK3AfOBcGC2qq4TkVu8\n658HhgD/FhEF1gE3uRWPCaLKge2K98OFf4WTbqhTdVFJWQUPzF3DuyuyOHdoPH+ZOsraD4xxiat/\nWao6D5hXbdnzPq8XA4GZdd00PZ4K+OpxWPgodOoH186BbiPqVERWXjE3v7KMdTsP8KtzBnLbmf0J\nC7P2A2PcYj+3jDsO7IK5P3fmUx45DaY8Aa1j6lTE4tRcbn39B8rKPfzz+mQmDbH2A2PcZknBBN6W\nz+Hd6VBWDJc8B6OuPv4+PlSVl75N58GPNpDYuQ2zrk+mX5e6JRRjTP1YUjCBU1EGXz4I3/wNug6D\nK/4FXQbVqYiSsgp+/e4a5v6QxTlD4/nLlSOJjarf5DrGmLqzpGACI28HzLkJMr93GpInPwyR0XUq\nYmdeMTe/spw1WfncefYAZpw1wNoPjGlklhRMw234EN77pdMP4fLZMPyyOhexJC2XW1/7gdJyDy9c\nn8w5Q639wJhgsKRg6q+8FD77HXz3PHQf5VQXdepbpyJUlZcXb+dPH66nd+c2zLoumf5drf3AmGCx\npGDqJzcV5twAu1bBuF/C2X+AiNZ1LuYP76/j34u3M2lwV/561SjaWfuBMUFlScHU3Zo58MGdEBYO\nV70Ogy+oVzHfpeXy78Xb+ckpffj9RcOs/cCYJsCSgvHfoYPwyUz44d/Qayxc9qIzhlE9eDzKQ/M2\n0K1dFDPPH2IJwZgmwpKC8c/ejU510d71MOEuOPN/ILz+VT0frN7Jqsx8nrhiJNGtwgMYqDGmISwp\nmGNThZWvw7x7ILINXPsO9D+7QUWWlFXw2CebGNq9HT8e3TNAgRpjAsGSgqldaSF8dDesfhMST4NL\nX4B23Rtc7MuL08nKK+bRy04g3KqNjGlSLCmYmu1a7VQX7UuDib+G0+9xGpYbaH/RIZ7+cisTB3Vh\nwoC4AARqjAkkSwrmSKqw7EX45NcQ3RGufx+STgtY8X//ciuFpeU8cP6QgJVpjAkcSwrmsOI8+GAG\nrH/PaTf48T+gbeB+zW/PLeKVJelcmdyLQd1iA1auMSZwLCkYR9ZyePsGOJAF5/wvnHI7hIUF9BCP\nfbKJiLAwfnWOTaFhTFNlSSHUqcKSZ+Gz30NsN7jhY+g1JuCHWb59Px+t2cUdkwbQtV1UwMs3xgSG\nJYVQdnAf/PcXsPkTGHwhXPy0044QYKrKnz9aT5fY1kw/vW5jIxljGpclhVCVtRz+cx0UZcP5j8GY\n6XWaN7kuPlm7mx925PHIpSNoa3MrG9Ok2V9oqPp4plN1dNOn0GO0a4c5VO7hkU82MjA+hiuS6zck\nhjGm8QS2JdE0DyX5kLUMRl/jakIAeO277WzPPcgDU4ZYRzVjmgFLCqFo2yJQD/Q909XD5BeX8eQX\nW5jQP46JA7u4eixjTGBYUghFaSkQ2RYSTnb1MM+mbCW/uIwHpgxGXGqvMMYEliWFUJSaAokTIKKV\na4fI2HeQf32bzqWjExjWo71rxzHGBJYlhVCTtwP2pUI/d6uOnvh0EwLcc551VDOmObGkEGpSU5xn\nF9sTVmfm8d7KnfzstCS6t4927TjGmMCzpBBq0hZAbHfoMsiV4p2Oahvo3LYVt5zRz5VjGGPcY0kh\nlHg8sG0h9J3oWke1zzfs5btt+7jz7AHERtV/ZjZjTHBYUgglu1fDwVzXqo7KKjw8/PEG+nZpy1Vj\nertyDGOMuywphJK0yvaEia4U/+bSDNKyi3jg/CFEhtt/LWOaI1f/ckVksohsEpGtIjKzhvXtReQD\nEVklIutE5AY34wl5qSnQdRjExge86IKSMv722WbGJHXi7CFdA16+MaZxuJYURCQceAY4HxgKTBOR\nodU2uxVYr6ojgYnA/4mIezfPh7KyYtixxLVbUf+xMI3cokP8z5Qh1lHNmGbMzSuFMcBWVU1T1UPA\nm8DF1bZRIFacs0gMsA8odzGm0LX9W6godaU9YVd+MS8sSuPiUT0Y2atDwMs3xjQeN5NCTyDD532m\nd5mvp4EhwE5gDXCHqnqqFyQi00VkmYgsy87Odiveli1tAYS3gj6nBLzoJ+ZvRhXuOded21yNMY0n\n2K2B5wErgR7AKOBpEWlXfSNVnaWqyaqa3KWLDaxWL2kp0GsstGob0GLX7cxn7opMbhifSK9ObQJa\ntjGm8R03KYjI7SJSn+m4sgDfAfQTvMt83QDMVcdWYBswuB7HMsdSmA271wT8riNV5eF5G2kfHckv\nz+wf0LKNMcHhz5VCPLBURN7y3k3kbyviUmCAiCR5G4+vAt6vts0OYBKAiMQDg4A0P8s3/tq20HkO\ncCPzws3ZfL01hxlnDaB9tHVUM6YlOG5SUNXfAAOAF4GfAltE5CEROeYYBqpaDtwGzAc2AG+p6joR\nuUVEbvFu9ifgVBFZA3wB3K+qOfX+NKZmqSkQ1QG6jwpYkeUVHh6at4E+ndtw7bg+ASvXGBNcfk3H\nqaoqIruB3Th3B3UE5ojIZ6p63zH2mwfMq7bseZ/XO4Fz6xO48ZOq057Q9wwICw9YsXOWZ7J5TyHP\nXnMirSKC3TRljAkUf9oU7hCR5cBjwDfACFX9BXAScJnL8ZmGyt0KB7IC2p5QVFrOXz7bzIm9O3D+\n8G4BK9cYE3z+XCl0Ai5V1e2+C1XVIyIXuhOWCRgXhsp+YVEaewtKee7ak6yjmjEtjD/X/R/jdCoD\nQETaichYAFXd4FZgJkDSUqBjInRKCkhxew+U8I+FaUwZ0Y2T+tTnpjRjTFPmT1J4Dij0eV/oXWaa\nuooy2LYooFcJf/18M+UeD/edZ3cOG9MS+ZMURFW18o23x7FfDdQmyLKWw6GCgN2KunlPAf9ZmsF1\n4xJJjAtsJzhjTNPgT1JIE5EZIhLpfdyB9SVoHlJTAIGk0wNS3MPzNtC2dQS3n2Ud1YxpqfxJCrcA\np+L0Rs4ExgLT3QzKBEhaCvQYDdENr/v/eksOKZuyuf2s/nRsawPZGtNSHbcaSFX34vRGNs1JyQHI\nXAYT7mxwUR6P8tC8DSR0jOb6UxIbHpsxpsk6blIQkSjgJmAYEFW5XFVvdDEu01DpX4NWBKSR+d0V\nWazfdYAnrxpFVGTgOsAZY5oef6qPXgG64YxouhBnYLsCN4MyAZCWApFtoNeYBhVTfKiCJz7dxMiE\n9lx0Qo8ABWeMaar8SQr9VfW3QJGq/hu4AKddwTRlqSnQZzxEtG5QMbO/2cau/BJ+PWUIYWHWUc2Y\nls6fpFDmfc4TkeFAe8Am4W3K8jMhd0uDb0XNKSzluQWpnDM0nrF9OwcoOGNMU+ZPf4NZ3vkUfoMz\n9HUM8FtXozINUzW0xcQGFfPk51soLqtg5vnWUc2YUHHMpCAiYcABVd0PfAX0bZSoTMOkLYCYeOg6\ntN5FpGYX8vr3O7h6TG/6dYkJXGzGmCbtmNVH3t7LtQ6NbZogj8dJCn0nQgMGq3vk441ER4Zzx9kD\nAhWZMaYZ8KdN4XMRuUdEeolIp8qH65GZ+tmzFg7mNOhW1O/Scvls/R5+MbEfcTENa6g2xjQv/rQp\nTPU+3+qzTLGqpKYprWHtCZUd1bq3j+KmCYEZWdUY03z406PZzgzNSWoKdBkC7brXa/cPVu9kVWY+\n/3fFSOuoZkwI8qdH8/U1LVfVlwMfjmmQshLYsRiS69fZvKSsgsc+2cTQ7u348eieAQ7OGNMc+FN9\ndLLP6yhgEvADYEmhqdmxGMpL6l119PLidLLyinns8hOso5oxIcqf6qPbfd+LSAfgTdciMvWXtgDC\nIp2ezHW0v+gQf/9yK2cO6sL4/nGBj80Y0yz4c/dRdUWAtTM0RWkpzlhHrever+DvX26lqLScB6YM\ncSEwY0xz4U+bwgc4dxuBk0SGAm+5GZSph6Jc2LUazvyfOu+anlPEK0vSmXpyLwbGx7oQnDGmufCn\nTeEJn9dbsxFFAAAU80lEQVTlwHZVzXQpHlNf2xYAWq/xjh6bv5HI8DDuOntgwMMyxjQv/iSFHcAu\nVS0BEJFoEUlU1XRXIzN1k5oCrds7M63VwfLt+5m3Zjd3nj2Aru2ijr+DMaZF86dN4W3A4/O+wrvM\nNBWqTiNz0mkQ5n/fAlXlzx+tp2tsa6afbn0RjTH+JYUIVT1U+cb72ibpbUpyUyE/o85VRx+v3c0P\nO/K4+9yBtGnlz0WjMaal8ycpZIvIjyrfiMjFQI57IZk6qxrawv+kcKjcw6OfbGRQfCyXn9TLpcCM\nMc2NPz8PbwFeE5Gnve8zgRp7OZsgSVsAHXpDJ/+rgF5Zsp3tuQd56YaTCbeOasYYL386r6UC40Qk\nxvu+0PWojP8qymHbVzDsx34PlZ2x7yB/+XQTpw/swhkDu7gcoDGmOTlu9ZGIPCQiHVS1UFULRaSj\niDzoT+EiMllENonIVhGZWcP6e0VkpfexVkQqbFjuOtr5A5Qe8Ls9weNR7p2zChHh4UtHIA2Yc8EY\n0/L406ZwvqrmVb7xzsI25Xg7iUg48AxwPk6Ht2kicsRUYKr6uKqOUtVRwAPAQlXdV5cPEPJSUwCB\npDP82vyVJdtZkraP3144hJ4dot2NzRjT7PiTFMJFpGqmFRGJBvyZeWUMsFVV07x3LL0JXHyM7acB\nb/hRrvGVlgLdR0Kb419gpecU8cjHG5k4qAtXJlvjsjHmaP4khdeAL0TkJhH5GfAZ8G8/9usJZPi8\nz/QuO4qItAEmA+/Usn66iCwTkWXZ2dl+HDpElBZA5lK/qo4qPMo9b68iIlx45NITrNrIGFOj4yYF\nVX0UeBAYAgwC5gN9AhzHRcA3tVUdqeosVU1W1eQuXaxhtEr6N+Ap9+tW1H99s41l2/fzh4uG0a29\n9Vw2xtTM31FS9+AMincFcBawwY99sgDfOooE77KaXIVVHdVdWgpEREPvccfcbOveQh6bv4mzh8Rz\n6Yk2eY4xpna13pIqIgNx6vmn4XRW+w8gqupvD6mlwAARScJJBlcBV9dwnPbAGcC1dQvdkJoCfU6F\niNqbeMorPNz99iratArnoUuHW7WRMeaYjtVPYSOwCLhQVbcCiMhd/hasquUichtOdVM4MFtV14nI\nLd71z3s3/THwqaoW1ecDhKz8LMjZBKOPnUtnLUpjVUYeT00bTddYqzYyxhzbsZLCpTi/7lNE5BOc\nu4fq9DNTVecB86ote77a+5eAl+pSrsHpxQzHbGTetLuAv322hSkjunHRCd0bJy5jTLNWa5uCqv5X\nVa8CBgMpwJ1AVxF5TkTObawATS3SUqBtF+g6rMbVZRUe7n57JbFREfzpYqs2Msb4x5+7j4pU9XVV\nvQinsXgFcL/rkZnaVQ6V3XcihNX8T/hsSiprsw7w5x8Pp3OMP91KjDGmjnM0q+p+7+2hk9wKyPhh\nzzooyq71VtR1O/P5+5dbuHhUDyYPt2ojY4z/6pQUTBNROVR2De0Jh8o93P3WKjq2bcUff1Rz1ZIx\nxtTGZlZpjlJTIG4QtOtx1KqnvtjCxt0FvPiTZDq0sbmQjDF1Y1cKzU1ZCWz/1mlPqGZVRh7PLUzl\n8pMSmDQkvtFDM8Y0f5YUmpuM76C8+Kiqo5KyCu5+exVdYlrz2wuH1rKzMcYcm1UfNTdpCyAsAhIn\nHLH4r59tZuveQv594xjaR0cGJzZjTLNnVwrNTVoKJJwMrWOrFi3fvo9Zi9KYNqaXzaRmjGkQSwrN\nycF9sHPlEbeiFh+q4J63V9OjfTT/c4FVGxljGsaqj5qTbQsBPaI94fH5m9iWU8TrPxtLTGv75zTG\nNIxdKTQnqSnQuh30OBGA79Jy+de327j+lD6c2j8uyMEZY1oCSwrNharTnpB4GoRHUFRazj1zVtGr\nYxtmnj842NEZY1oISwrNxb40yNtRVXX0yMcbydxfzBNXjKRNK6s2MsYEhiWF5qJyqOy+Z/LN1hxe\nWbKdG8cnMSapU1DDMsa0LJYUmou0FGjfi4K2vblvzmr6xrXl3vMGBTsqY0wLY0mhOfBUwLavoO9E\n/jxvI7vyi3niypFERYYHOzJjTAtjSaE52LkCSvJZF30iby7NYPrp/Tixd8dgR2WMaYEsKTQHqc5Q\n2b9a2p4BXWO48+wBQQ7IGNNS2W0rzUFaCplRA9h6IJr//mSUVRsZY1xjVwpNXWkhnozv+bBwMLdO\n7MeIhPbBjsgY04JZUmjiCjYvJMxTxvYOY7ntLKs2Msa4y5JCE7fsy7mUaCTXXzmVVhH2z2WMcZed\nZZqweWt20SN3CXs7nsiQ3l2DHY4xJgRYUmiicgpL+du7XzEoLJOeJ50f7HCMMSHCkkITpKr85t21\njDq0EoDw/mcFOSJjTKiwW1KboPdX7eSTdbuZ3ycdCuIgfkSwQzLGhAi7Umhi9h4o4XfvrWN0r/YM\nLFoOfc+AMPtnMsY0DjvbNCGqygNz11BSVsFTk6KQwj1HTL1pjDFus6TQhLzzQxZfbNzLvecNotf+\n75yFfScGMyRjTIhxNSmIyGQR2SQiW0VkZi3bTBSRlSKyTkQWuhlPU7Yrv5g/frCOMYmduHF8kjPe\nUef+0KFXsEMzxoQQ1xqaRSQceAY4B8gElorI+6q63mebDsCzwGRV3SEiIXkzvqpy35zVlFcoj19x\nAmGeQ7D9Gxh1TbBDM8aEGDevFMYAW1U1TVUPAW8CF1fb5mpgrqruAFDVvS7G02S9uTSDRVtyeGDK\nYPp0bgsZ30PZwaqpN40xprG4mRR6Ahk+7zO9y3wNBDqKyAIRWS4i19dUkIhMF5FlIrIsOzvbpXCD\nI2PfQR78cD2n9O3MtWP7OAvTFoCEQ+KEoMZmjAk9wW5ojgBOAi4AzgN+KyIDq2+kqrNUNVlVk7t0\n6dLYMbrG41Huf2c1AI9dfgJhYeKsSEuBhGSIshFRjTGNy82kkAX4tpImeJf5ygTmq2qRquYAXwEj\nXYypSXn1u+18m5rLby4cSq9ObZyFxfudmdbsVlRjTBC4mRSWAgNEJElEWgFXAe9X2+Y9YIKIRIhI\nG2AssMHFmJqM9JwiHp63kdMHduGqk31y57avQD12K6oxJihcu/tIVctF5DZgPhAOzFbVdSJyi3f9\n86q6QUQ+AVYDHuCfqrrWrZiaCo9HuXfOKiLChUcvG4GIHF6ZmgKtYp3qI2OMaWSujn2kqvOAedWW\nPV/t/ePA427G0dTM/mYbS9P388QVI+nePvrIlWkpTgNzeGRwgjPGhLRgNzSHnM17Cnh8/iYmDe7K\nZSdWuxlr3zbYn263ohpjgsaSQiN6b2UWlz37LW1bR/DwpdWqjcC5FRWskdkYEzQ2dHYjKCot5/fv\nr2PO8kxO7N2BJ68aTdd2UUdvmJYC7XpCnM3FbIwJDksKLlublc/tb6wgPbeIGWf1Z8akAUSE13CB\n5qmAtIUw+AKofgVhjDGNxJKCSzweZfY323j0k410btua1382jlP6da59h10roSTPqo6MMUFlScEF\n2QWl3PP2KhZuzubcofE8etkJdGzb6tg7paY4z30nuh2eMcbUypJCgH21OZtfvbWKgpIy/nTJcK4d\n2/voBuWapC1wpt2MaTnDeBhjmh9LCgFyqNzDE59uYtZXaQyMj+G1n41lULdYP3cugozvYOzN7gZp\njDHHYUkhALblFDHjjRWsycrn2nG9+c0FQ4mKDPe/gO2LoeKQtScYY4LOkkIDqCpzf8jit++tJTI8\njH9cdxLnDetW94LSUiC8NfQ5NfBBGmNMHVhSqKeCkjJ+89+1vLdyJ2OSOvG3qaPo0SH6+DvWJDUF\neo+FyHrub4wxAWJJoR5W7NjPHW+uJCuvmLvPGcgvz+xPeFg9+xYU7IG962DS7wMbpDHG1IMlhTrw\neJTnv0rlL59uJr5dFP+ZPo7kxE4NK7RyaAsb78gY0wRYUvDT3gMl3PXWSr7ZmssFI7rz0KUjaB8d\ngJFM01IguhN0C5m5hYwxTZglBT98uXEP97y9muJDFTx62QiuTO7lX9+D41F1rhT6ngFhNjahMSb4\nLCkcQ2l5BY98vJF/fZPOkO7t+Pu00fTvGhO4A2RvgoJddiuqMabJsKRQi617C7n9jRVs2HWAG8Yn\ncv/kwXXre+CPNBvawhjTtFhSqEZVeWtZBn94fz3RrcKZ/dNkzhoc787BUlOgU1/o2Med8o0xpo4s\nKfjILy7j13PX8NGaXYzv35m/Xjmq5nkPAqH8EKR/DSOvcqd8Y4ypB0sKXsu372PGGyvZc6CE+ycP\n5ubT+xJW374H/shcCmVFdiuqMaZJCfmkUOFRnknZypNfbKFnh2jm/OJURvXq4P6B0xaAhEHiae4f\nyxhj/BTSSWFXfjF3vrmS77bt45JRPfjTJcOJjQpA3wN/pKVAz5MguhESkDHG+Clkk8L8dbu5/53V\nlJV7+MuVI7n0xITGO3hxHmQth9PubrxjGmOMH0IuKZSUVfDgR+t5dckORvRsz1PTRpMU17Zxg0hf\nBOqx/gnGmCYnpJLCpt0F3P7GD2zeU8jNp/fl7nMH0SoiCD2JU1Mgsi0knNz4xzbGmGMImaTw6brd\n3P7GCmKjInn5xjGcPjCI016mpUDiBIg4zrzNxhjTyEImKQzv2Z5zh3Xj9xcNJS6mdfAC2b8d9qXB\nmOnBi8EYY2oRMkmhR4do/j5tdPACKCuBjCWw4lXnvbUnGGOaoJBJCo2uohx2rXT6I2xbCDu+g4pS\nkHAYfjl0GRTsCI0x5iiuJgURmQw8CYQD/1TVR6qtnwi8B2zzLpqrqv/rZkyuUYXsjZC20EkC6d9A\nab6zLn44nPwzZ4jsPqdC69jgxmqMMbVwLSmISDjwDHAOkAksFZH3VXV9tU0XqeqFbsXhqrwdh5PA\ntq+gcI+zvGMiDLvESQKJp0NMEBu1jTGmDty8UhgDbFXVNAAReRO4GKieFJqPolxvAljoJIP93guc\ntl0g6QwnCSSdYaOeGmOaLTeTQk8gw+d9JjC2hu1OFZHVQBZwj6quq76BiEwHpgP07t3bhVBrUVoI\n2789nAT2rHGWt4p1bikde7OTBLoOgUDMxGaMMUEW7IbmH4DeqlooIlOA/wIDqm+kqrOAWQDJycnq\nWjTlh5zRSyuTQNYy8JRDeCvoNRbO+g0kTYQeoyE82F+dMcYEnptntiygl8/7BO+yKqp6wOf1PBF5\nVkTiVDXHxbgO83hg9+rDSWDHYig76Ixe2n0UnHq7cyXQexxERjdKSMYYE0xuJoWlwAARScJJBlcB\nV/tuICLdgD2qqiIyBggDcl2LSBVyU2HbAicJpC+C4v3OurhBMPpaJwkkjofojq6FYYwxTZVrSUFV\ny0XkNmA+zi2ps1V1nYjc4l3/PHA58AsRKQeKgatU1Z3qoc3z4cO74ID3YqVdAgya4iSBpNOhXXdX\nDmuMMc2JqxXjqjoPmFdt2fM+r58GnnYzhiqx3Z35C077ldObuFNfaxw2xphqQqe1tPsJMPWVYEdh\njDFNWhDGjTbGGNNUWVIwxhhTxZKCMcaYKpYUjDHGVLGkYIwxpoolBWOMMVUsKRhjjKliScEYY0wV\ncWtUCbeISDawvZ67xwGNM9he82Dfx5Hs+zjMvosjtYTvo4+qHnfGr2aXFBpCRJapanKw42gq7Ps4\nkn0fh9l3caRQ+j6s+sgYY0wVSwrGGGOqhFpSmBXsAJoY+z6OZN/HYfZdHClkvo+QalMwxhhzbKF2\npWCMMeYYLCkYY4ypEjJJQUQmi8gmEdkqIjODHU8wiUgvEUkRkfUisk5E7gh2TMEmIuEiskJEPgx2\nLMEmIh1EZI6IbBSRDSJySrBjChYRucv7N7JWRN4Qkahgx+S2kEgKIhIOPAOcDwwFponI0OBGFVTl\nwN2qOhQYB9wa4t8HwB3AhmAH0UQ8CXyiqoOBkYTo9yIiPYEZQLKqDseZa/6q4EblvpBICsAYYKuq\npqnqIeBN4OIgxxQ0qrpLVX/wvi7A+aPvGdyogkdEEoALgH8GO5ZgE5H2wOnAiwCqekhV84IbVVBF\nANEiEgG0AXYGOR7XhUpS6Alk+LzPJIRPgr5EJBEYDXwX3EiC6m/AfYAn2IE0AUlANvAvb3XaP0Wk\nbbCDCgZVzQKeAHYAu4B8Vf00uFG5L1SSgqmBiMQA7wB3quqBYMcTDCJyIbBXVZcHO5YmIgI4EXhO\nVUcDRUBItsGJSEecGoUkoAfQVkSuDW5U7guVpJAF9PJ5n+BdFrJEJBInIbymqnODHU8QjQd+JCLp\nONWKZ4nIq8ENKagygUxVrbxynIOTJELR2cA2Vc1W1TJgLnBqkGNyXagkhaXAABFJEpFWOI1F7wc5\npqAREcGpM96gqn8JdjzBpKoPqGqCqibi/L/4UlVb/K/B2qjqbiBDRAZ5F00C1gcxpGDaAYwTkTbe\nv5lJhECje0SwA2gMqlouIrcB83HuIJitquuCHFYwjQeuA9aIyErvsl+r6rwgxmSajtuB17w/oNKA\nG4IcT1Co6nciMgf4AeeOvRWEwHAXNsyFMcaYKqFSfWSMMcYPlhSMMcZUsaRgjDGmiiUFY4wxVSwp\nGGOMqWJJwRgvEakQkZU+j4D15BWRRBFZG6jyjHFLSPRTMMZPxao6KthBGBNMdqVgzHGISLqIPCYi\na0TkexHp712eKCJfishqEflCRHp7l8eLyLsissr7qBwaIVxEXvCOz/+piER7t5/hndtitYi8GaSP\naQxgScEYX9HVqo+m+qzLV9URwNM4o6oC/B34t6qeALwGPOVd/hSwUFVH4owbVNl7fgDwjKoOA/KA\ny7zLZwKjveXc4taHM8Yf1qPZGC8RKVTVmBqWpwNnqWqadyDB3araWURygO6qWuZdvktV40QkG0hQ\n1VKfMhKBz1R1gPf9/UCkqj4oIp8AhcB/gf+qaqHLH9WYWtmVgjH+0Vpe10Wpz+sKDrfpXYAzM+CJ\nwFLvhC7GBIUlBWP8M9XnebH39bccnp7xGmCR9/UXwC+gau7n9rUVKiJhQC9VTQHuB9oDR12tGNNY\n7BeJMYdF+4waC848xZW3pXYUkdU4v/aneZfdjjND2b04s5VVjiZ6BzBLRG7CuSL4Bc7MXTUJB171\nJg4Bngrx6S9NkFmbgjHH4W1TSFbVnGDHYozbrPrIGGNMFbtSMMYYU8WuFIwxxlSxpGCMMaaKJQVj\njDFVLCkYY4ypYknBGGNMlf8H9/Yf9vD0t+AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aa721a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"acc\"],label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"],label=\"val\")\n",
    "plt.legend()\n",
    "plt.title(\"Model Performance\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.savefig(\"cnn_loss.png\",dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 9086945.,        0.,        0.,  8313083.,        0.,        0.,\n",
       "         8400089.,        0.,        0.,  9199883.]),\n",
       " array([ 1. ,  1.3,  1.6,  1.9,  2.2,  2.5,  2.8,  3.1,  3.4,  3.7,  4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEDCAYAAADOc0QpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21486f7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(real_seqs.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 8747965.,        0.,        0.,  8754235.,        0.,        0.,\n",
       "         8752914.,        0.,        0.,  8744886.]),\n",
       " array([ 1. ,  1.3,  1.6,  1.9,  2.2,  2.5,  2.8,  3.1,  3.4,  3.7,  4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEDCAYAAADOc0QpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXZIaMu6S1JBxl6SGjLskNWTcJamh/waRgLuWY2u1wAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c5e56750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(fake_seqs.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_exp = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02242070699589593, 0.99714285693849836]\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test_exp, y_test, verbose=0)\n",
    "print scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-385-e6f56028fb53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_vecor_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#model.add(Dropout(0.5))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#model.add(Dropout(0.5))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RNN' is not defined"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_length))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(LSTM(100))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "# Final evaluation of the model\n",
    "#scores = model.evaluate(X_test[:100], y_test[:100], verbose=0)\n",
    "#print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s     \n",
      "[0.70228164434432983, 0.44000000953674318]\n",
      "Accuracy: 44.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print scores\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  3.,  3.,  2.,  2.,  4.,  3.,  3.,  2.,  1.,  3.,  1.,\n",
       "        3.,  4.,  2.,  4.,  4.,  4.,  2.,  2.,  2.,  1.,  3.,  3.,  3.,\n",
       "        1.,  1.,  1.,  3.,  2.,  4.,  1.,  2.,  1.,  1.,  3.,  2.,  1.,\n",
       "        3.,  2.,  1.,  1.,  1.,  2.,  1.,  3.,  4.,  2.,  4.,  3.,  2.,\n",
       "        1.,  4.,  3.,  3.,  3.,  4.,  2.,  1.,  4.,  2.,  2.,  2.,  2.,\n",
       "        4.,  4.,  2.,  1.,  2.,  4.,  2.,  2.,  2.,  1.,  3.,  2.,  4.,\n",
       "        2.,  1.,  3.,  1.,  3.,  2.,  2.,  2.,  1.,  3.,  3.,  2.,  2.,\n",
       "        1.,  3.,  3.,  3.,  3.,  2.,  2.,  2.,  2.,  2.,  1.,  1.,  3.,\n",
       "        1.,  1.,  1.,  3.,  3.,  2.,  4.,  2.,  4.,  3.,  3.,  4.,  3.,\n",
       "        3.,  1.,  3.,  1.,  1.,  2.,  2.,  4.,  3.,  4.,  3.,  2.,  1.,\n",
       "        4.,  3.,  1.,  1.,  3.,  3.,  2.,  4.,  3.,  4.,  2.,  1.,  1.,\n",
       "        2.,  2.,  1.,  3.,  4.,  2.,  2.,  1.,  4.,  1.,  3.,  3.,  2.,\n",
       "        1.,  1.,  3.,  2.,  2.,  4.,  3.,  3.,  2.,  4.,  3.,  2.,  2.,\n",
       "        4.,  2.,  2.,  1.,  3.,  2.,  4.,  3.,  3.,  3.,  4.,  2.,  3.,\n",
       "        1.,  2.,  1.,  3.,  1.,  2.,  1.,  3.,  3.,  3.,  3.,  2.,  4.,\n",
       "        3.,  3.,  1.,  3.,  1.,  1.,  3.,  3.,  3.,  3.,  1.,  3.,  1.,\n",
       "        1.,  3.,  1.,  3.,  3.,  1.,  1.,  1.,  3.,  4.,  3.,  1.,  3.,\n",
       "        3.,  4.,  4.,  3.,  2.,  2.,  4.,  3.,  2.,  2.,  2.,  4.,  3.,\n",
       "        4.,  2.,  4.,  2.,  2.,  4.,  1.,  2.,  2.,  4.,  3.,  1.,  3.,\n",
       "        3.,  2.,  4.,  3.,  1.,  3.,  3.,  1.,  1.,  3.,  3.,  1.,  3.,\n",
       "        1.,  1.,  3.,  3.,  3.,  3.,  1.,  4.,  3.,  2.,  1.,  2.,  4.,\n",
       "        3.,  4.,  4.,  3.,  3.,  3.,  3.,  1.,  3.,  3.,  2.,  1.,  3.,\n",
       "        2.,  4.,  3.,  4.,  1.,  1.,  2.,  4.,  2.,  1.,  1.,  1.,  3.,\n",
       "        2.,  2.,  4.,  4.,  1.,  3.,  2.,  2.,  4.,  2.,  4.,  3.,  4.,\n",
       "        4.,  2.,  2.,  2.,  1.,  2.,  3.,  1.,  1.,  3.,  3.,  2.,  1.,\n",
       "        3.,  3.,  3.,  2.,  2.,  1.,  4.,  2.,  1.,  3.,  3.,  2.,  1.,\n",
       "        2.,  2.,  1.,  1.,  1.,  3.,  3.,  3.,  1.,  4.,  4.,  2.,  4.,\n",
       "        3.,  2.,  2.,  1.,  3.,  2.,  1.,  4.,  1.,  3.,  4.,  3.,  2.,\n",
       "        4.,  2.,  2.,  4.,  3.,  3.,  1.,  2.,  2.,  1.,  3.,  4.,  3.,\n",
       "        1.,  4.,  1.,  2.,  1.,  2.,  2.,  2.,  3.,  3.,  2.,  1.,  2.,\n",
       "        2.,  2.,  4.,  3.,  4.,  2.,  2.,  4.,  3.,  3.,  1.,  2.,  1.,\n",
       "        2.,  3.,  2.,  4.,  3.,  4.,  4.,  3.,  3.,  2.,  2.,  4.,  3.,\n",
       "        3.,  1.,  4.,  2.,  4.,  3.,  1.,  3.,  2.,  2.,  2.,  4.,  3.,\n",
       "        3.,  4.,  3.,  3.,  1.,  3.,  3.,  4.,  2.,  1.,  1.,  1.,  3.,\n",
       "        2.,  2.,  1.,  2.,  2.,  4.,  4.,  4.,  3.,  3.,  4.,  4.,  2.,\n",
       "        4.,  3.,  2.,  2.,  1.,  4.,  4.,  3.,  2.,  4.,  3.,  2.,  4.,\n",
       "        3.,  4.,  3.,  4.,  3.,  3.,  1.,  1.,  3.,  4.,  4.,  2.,  1.,\n",
       "        2.,  4.,  2.,  2.,  4.,  3.,  2.,  2.,  4.,  4.,  4.,  4.,  2.,\n",
       "        2.,  4.,  4.,  4.,  2.,  2.])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_seqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0., ...,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51714285714285713"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_train==1)/float(y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog']\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "# define the document\n",
    "text = 'The quick brown fox jumped over the lazy dog.'\n",
    "# tokenize the document\n",
    "result = text_to_word_sequence(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[3.0, 6.0, 4.0, 6.0, 9.0, 7.0, 3.0, 9.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "# define the document\n",
    "text = 'The quick brown fox jumped over the lazy dog.'\n",
    "# estimate the size of the vocabulary\n",
    "words = set(text_to_word_sequence(text))\n",
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "# integer encode the document\n",
    "result = one_hot(text, round(vocab_size*1.3))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[5, 5, 5, 2]\n"
     ]
    }
   ],
   "source": [
    "seq = 'ACGT'\n",
    "text = \" \".join(seq)\n",
    "# estimate the size of the vocabulary\n",
    "words = set(text_to_word_sequence(text))\n",
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "# integer encode the document\n",
    "result = one_hot(text, 6)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_vec(sequence):\n",
    "    sequence = sequence.replace(\" \",\"\")\n",
    "    sequence = sequence.replace(\"\\n\",\"\")\n",
    "    vec = np.zeros(len(sequence))\n",
    "    for i,s in enumerate(sequence):\n",
    "        c = 0\n",
    "        if s == \"A\":\n",
    "            c = 1\n",
    "        elif s == \"C\":\n",
    "            c = 2\n",
    "        elif s == \"G\":\n",
    "            c = 3\n",
    "        elif s == \"T\":\n",
    "            c = 4\n",
    "        \n",
    "        # N means unknown, randomly choose\n",
    "        # Note: this happens very little\n",
    "        if c == 0:\n",
    "            c = np.random.choice([1,2,3,4])\n",
    "        \n",
    "        vec[i] = c\n",
    "            \n",
    "    return vec\n",
    "\n",
    "def vec_to_seq(vec):\n",
    "    seq = \"\"\n",
    "    for i in vec:\n",
    "        if i == 1:\n",
    "            seq += \"A\"\n",
    "        if i == 2:\n",
    "            seq += \"C\"\n",
    "        if i == 3:\n",
    "            seq += \"G\"\n",
    "        if i == 4:\n",
    "            seq += \"T\"\n",
    "    return seq\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real Sequences\n",
    "big_seq = \"\"\n",
    "seq_file = open(\"bigseq.txt\",\"rb\")\n",
    "for line in seq_file:\n",
    "    big_seq += line    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print np.random.choice([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
